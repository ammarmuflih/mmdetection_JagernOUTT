{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from fastai.script import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.distributed import *\n",
    "from fastprogress import fastprogress\n",
    "from torchvision.models import *\n",
    "from fastai.vision.models import *\n",
    "from pathlib import Path\n",
    "\n",
    "from mmdet.models.backbones import *\n",
    "from mmdet.models.backbones.base_backbone import ClassifierPretrainWrapper\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "fastprogress.MAX_COLS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, woof, bs, workers=None):\n",
    "    if   size <= 128:\n",
    "        path = URLs.IMAGEWOOF_160 if woof else URLs.IMAGENETTE_160\n",
    "    elif size <= 224: \n",
    "        path = URLs.IMAGEWOOF_320 if woof else URLs.IMAGENETTE_320\n",
    "    else:\n",
    "        path = URLs.IMAGEWOOF if woof else URLs.IMAGENETTE\n",
    "    path = untar_data(path)\n",
    "\n",
    "    n_gpus = num_distrib() or 1\n",
    "    if workers is None:\n",
    "        workers = min(8, num_cpus() // n_gpus)\n",
    "\n",
    "    return (ImageList\n",
    "            .from_folder(path)\n",
    "            .split_by_folder(valid='val')\n",
    "            .label_from_folder()\n",
    "            .transform(([flip_lr(p=0.5), cutout(n_holes=(1, 4), length=(10, 160), p=0.5)], []), size=size)\n",
    "            .databunch(bs=bs, num_workers=workers)\n",
    "            .presize(size, scale=(0.35, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes: Param(\"Class count\", int) = 10\n",
    "arch_name: Param(\"Backbone name, used for dumping\", str) = 'scarlet_c'\n",
    "\n",
    "# Model description\n",
    "backbone = ScarletC(out_indices=None)\n",
    "model = ClassifierPretrainWrapper(backbone, input_channels=1280, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gpu: Param(\"GPU to run on\", str) = None\n",
    "woof: Param(\"Use imagewoof (otherwise imagenette)\", int) = True\n",
    "size: Param(\"Size (px: 128, 192, 224)\", int) = 320\n",
    "mom: Param(\"Momentum\", float) = 0.9\n",
    "eps: Param(\"epsilon\", float) = 1e-6\n",
    "epochs: Param(\"Number of epochs\", int) = 20\n",
    "bs: Param(\"Batch size\", int) = 64\n",
    "mixup: Param(\"Mixup\", float) = 0.\n",
    "opt: Param(\"Optimizer (adam, rms, sgd)\", str) = 'adam'\n",
    "dump: Param(\"Path to pretrained backbones\", Path) = Path('/mnt/nfs/Other/pytorch_pretrained_backbones/')\n",
    "\n",
    "gpu = setup_distrib(gpu)\n",
    "if gpu is None: \n",
    "    bs *= torch.cuda.device_count()\n",
    "\n",
    "opt_func = partial(optim.SGD, momentum=mom)\n",
    "\n",
    "data = get_data(size, woof, bs)\n",
    "bs_rat = bs / 256\n",
    "if gpu is not None:\n",
    "    bs_rat *= num_distrib()\n",
    "\n",
    "learn = Learner(data, model, wd=1e-2, opt_func=opt_func,\n",
    "                metrics=[accuracy, top_k_accuracy],\n",
    "                bn_wd=False, true_wd=True,\n",
    "                loss_func=LabelSmoothingCrossEntropy())\n",
    "if mixup: \n",
    "    learn = learn.mixup(alpha=mixup)\n",
    "learn = learn.to_fp16(dynamic=True)\n",
    "if gpu is None:      \n",
    "    learn.to_parallel()\n",
    "elif num_distrib() > 1: \n",
    "    learn.to_distributed(gpu) # Requires `-m fastai.launch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find(num_it=200, end_lr=10.)\n",
    "# learn.recorder.plot(skip_start=2, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr: Param(\"Learning rate\", float) = 1e-3\n",
    "if not gpu:\n",
    "    print(f'lr: {lr}; eff_lr: {lr * bs_rat}; size: {size}; mom: {mom}; eps: {eps}')\n",
    "lr *= bs_rat\n",
    "    \n",
    "    \n",
    "learn.fit_one_cycle(epochs, lr, div_factor=10, pct_start=0.3)\n",
    "if not (dump / arch_name).exists():\n",
    "    os.makedirs(str(dump / arch_name))\n",
    "learn.model.save_backbone(str(dump / arch_name / f\"{arch_name}__{datetime.now().strftime('%d_%m_%y__%H_%M_%S')}.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
